# ðŸ§  Local AI Research Assistant

This is a local voice-enabled AI assistant for summarizing research topics using a local LLM (Mistral via Ollama).

## Features
- ðŸŽ¤ Voice or text input
- ðŸ§  Local LLM (Mistral)
- ðŸ”ˆ Text-to-speech output
- Gradio-powered interface

## Run Locally
```bash
pip install -r requirements.txt
ollama run mistral
python app.py

